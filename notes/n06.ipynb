{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69c65dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "X_submit = pd.read_csv(\"/Users/henmi_note/Desktop/signate2/output/11__Stack/03__Ensemble/0902_2108/model_level_probas_is_submit.csv\", index_col=0)\n",
    "X_pretrain = pd.read_csv(\"/Users/henmi_note/Desktop/signate2/output/11__Stack/03__Ensemble/0902_2023/model_level_probas.csv\", index_col=0)\n",
    "y_pretrain = pd.read_csv(\"../output/11__Stack/03__Ensemble/0902_2023/y_test.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255dd2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32439"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "16f9331d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "X_bin = (X_pretrain>0.5).astype(int)\n",
    "\n",
    "scores = {\n",
    "    col: f1_score(\n",
    "        X_bin[col], y_pretrain\n",
    "    ) for col in X_bin.columns\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3614de00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000100000'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin(32)[2:].zfill(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "50039ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores\n",
    "\n",
    "num_cols = len(X_pretrain.columns)\n",
    "n_max = 2**num_cols\n",
    "scores_selected = []\n",
    "for i in range(n_max):\n",
    "    i_bin = bin(i)[2:].zfill(num_cols)\n",
    "    cols_selected = np.array(X_pretrain.columns)[\n",
    "        [j for j in range(num_cols) if i_bin[j] == \"1\"]\n",
    "    ]\n",
    "\n",
    "    # ナイーブ\n",
    "    # w = np.array([scores[col] for col in cols_selected])\n",
    "    w = np.ones(len(cols_selected))\n",
    "    X_weighted = (X_pretrain[cols_selected].dot(w/sum(w))>0.5).astype(int)\n",
    "\n",
    "    scores_selected.append(f1_score(\n",
    "        X_weighted, y_pretrain\n",
    "    ))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "15f0a565",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "i_bin = [bin(i)[2:].zfill(num_cols) for i in range(n_max)]\n",
    "cols = [\n",
    "        [X_pretrain.columns[j] for j in range(num_cols) if i_bin_[j] == \"1\"] for i_bin_ in i_bin\n",
    "    ]\n",
    "\n",
    "df_result = pd.DataFrame(\n",
    "    {\n",
    "        \"i_bin\": i_bin,\n",
    "        \"models\": cols,\n",
    "        \"scores\": scores_selected\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7eebd90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5973243340966614, 0.6070492974517743, 0.6115897556945592] 0.6053211290809983\n",
      "[0.5971231717635682, 0.6064870021464346, 0.6116171773334911] 0.6050757837478312\n",
      "[0.5967625030200532, 0.6067254948724063, 0.6116367076631978] 0.6050415685185525\n",
      "[0.5971953578336557, 0.6069212410501194, 0.6112556159848664] 0.6051240716228805\n",
      "[0.596042471042471, 0.6057210965435041, 0.6108223062381852] 0.6041952912747202\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "for top_k in [1, 3, 5, 10, 20]:\n",
    "\n",
    "    df_result_sorted = df_result.sort_values(\"scores\", ascending=False).reset_index(drop=True)\n",
    "    df_result_sorted.head()[\"models\"].tolist()\n",
    "\n",
    "    from collections import defaultdict\n",
    "    adict = {\n",
    "        k: 0 for k in X_pretrain.columns\n",
    "    }\n",
    "    for models_v in df_result_sorted.loc[:top_k, \"models\"]:\n",
    "        for v in models_v:\n",
    "            adict[v]+=1\n",
    "\n",
    "    new_w = np.array(list(adict.values()))\n",
    "    new_w = new_w / sum(new_w)\n",
    "\n",
    "    y_pred_tmp, y_true_tmp = (X_pretrain.dot(new_w)>0.5).astype(int).copy(), y_pretrain.copy()\n",
    "\n",
    "    cv = KFold(n_splits=3, random_state=42, shuffle=True)\n",
    "    scores_tmp = []\n",
    "    for idx, _ in cv.split(y_pred_tmp):\n",
    "        scores_tmp.append(\n",
    "            f1_score(\n",
    "                y_pred_tmp.iloc[idx], y_true_tmp.iloc[idx]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        scores_tmp, np.mean(scores_tmp)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd1ea13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MLP_PyT_emb',\n",
       " 'XGBoost',\n",
       " 'LightGBM_GBDT',\n",
       " 'LightGBM_DART',\n",
       " 'MLP_PyT_simple',\n",
       " 'RealMLP']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "715d2df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_submit = pd.read_csv(\"/Users/henmi_note/Desktop/signate2/output/11__Stack/03__Ensemble/0902_2154/model_level_probas_is_submit.csv\", index_col=0)\n",
    "models_selected = df_result_sorted[\"models\"].iloc[0]\n",
    "y_submit_1 = (X_submit[models_selected].mean(axis=1)>0.5).astype(int)\n",
    "np.save(\n",
    "    \"tmp\",\n",
    "    y_submit_1.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6b6f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_00000</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_00001</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_00002</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_00003</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_00004</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_32434</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_32435</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_32436</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_32437</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_32438</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32439 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1\n",
       "0            \n",
       "test_00000  1\n",
       "test_00001  0\n",
       "test_00002  0\n",
       "test_00003  1\n",
       "test_00004  0\n",
       "...        ..\n",
       "test_32434  1\n",
       "test_32435  1\n",
       "test_32436  1\n",
       "test_32437  0\n",
       "test_32438  0\n",
       "\n",
       "[32439 rows x 1 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_submit_1 と片方、結果はどれくらい違うのか？？\n",
    "y_submit_2 = pd.read_csv(\"../output/99_Submision/0902_2305__submit.csv\", index_col=0, header=None)\n",
    "y_submit_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cb29ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0804_2053',\n",
       " '0807_0129',\n",
       " '0813_0134',\n",
       " '0819_1724',\n",
       " '0819_1950',\n",
       " '0820_1501',\n",
       " '0821_1904',\n",
       " '0821_1907',\n",
       " '0821_1928',\n",
       " '0821_1929',\n",
       " '0822_1851',\n",
       " '0825_2227',\n",
       " '0826_0214',\n",
       " '0826_1524',\n",
       " '0827_0127',\n",
       " '0828_2133',\n",
       " '0829_1453',\n",
       " '0829_1458',\n",
       " '0901_1309',\n",
       " '0901_1311',\n",
       " '0901_1737',\n",
       " '0901_1745',\n",
       " '0902_1006',\n",
       " '0902_2137',\n",
       " '0902_2305',\n",
       " '0902_2312']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ラストは直近の結果の平均でも提出するか\n",
    "import json\n",
    "with open(\"/Users/henmi_note/Desktop/signate2/output/99_Submision/000__memo.json\", \"r\") as f:\n",
    "    memo = json.load(f)\n",
    "\n",
    "date_list = [\n",
    "    '0804_2053',\n",
    "    '0807_0129',\n",
    "    '0813_0134',\n",
    "    '0819_1724',\n",
    "    '0819_1950',\n",
    "    '0820_1501',\n",
    "    '0821_1904',\n",
    "    '0821_1907',\n",
    "    '0821_1928',\n",
    "    '0821_1929',\n",
    "    '0822_1851',\n",
    "    '0825_2227',\n",
    "    '0826_0214',\n",
    "    '0826_1524',\n",
    "    '0827_0127',\n",
    "    '0828_2133',\n",
    "    '0829_1453',\n",
    "    '0829_1458',\n",
    "    '0901_1309',\n",
    "    '0901_1311',\n",
    "    '0901_1737',\n",
    "    '0901_1745',\n",
    "    '0902_1006',\n",
    "    '0902_2137',\n",
    "    '0902_2305',\n",
    "    '0902_2312'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "832d0d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0804_2053': '最初の提出。特徴量はgoal(log), 時刻系特徴量の差分、通貨・国籍のワンホットエンコーディング',\n",
       " '0807_0129': 'xgboos、不均衡重み処理、テキスト処理なし、numericalデータのスケーリングなし、モデルのハイパラなし',\n",
       " '0813_0134': 'desc のトークン化＋主成分抽出データをテーブルに追加、XGBoost',\n",
       " '0819_1724': '成分（テキスト由来）100成分＋n_estimator=100の軽量lightGBM',\n",
       " '0819_1950': 'スタッキングモデル lightGBM, XGBoost,ベースモデル群+XGBoost のメタモデル',\n",
       " '0820_1501': 'HPTの結果を反映てスタッキングモデを設計',\n",
       " '0821_1904': 'テーブルデータ向けモ学習・予測。不均衡データ対策にランダムダウンサンプリングを採用。詳細はnote/n04.ipynb',\n",
       " '0821_1907': 'テーブルデータ向けモデルで学習・予測。不均衡データ対策にランダムダウンサンプリングを採用。詳細はnote/n04.ipynb',\n",
       " '0821_1928': 'テーブルデータ向けモデルで学習・予測。不均衡データ対策にランダムダウンサンプリングを採用。詳細はnote/n04.ipynb',\n",
       " '0821_1929': 'テーブルデータ向けモデルで学習・予測。不均衡データ対策にランダムダウンサンプリングを採用。詳細はnote/n04.ipynb',\n",
       " '0822_1851': 'ヤケクソ',\n",
       " '0825_2227': 'descのジャンル別モデルをスタッキングに追加。また、テキストベクトルを主成分化前のまま利用',\n",
       " '0826_0214': '新しいライブラリ',\n",
       " '0826_1524': 'k近傍法モデルをベースモデルに追加。スタッキングプロセスをOOFに準拠',\n",
       " '0827_0127': 'モデル由来のメタ特徴量をF1スコアの加重変更、メタモデル予測をOOF予測に変更',\n",
       " '0828_2133': '新規スタッキング。RealMLP, 特徴量サンプリングロジスティックモデル、Pytorchニューラルネットワーク',\n",
       " '0829_1453': 'メタモデルのマルチ化、embedding層ありMLPをベースモデルに追加',\n",
       " '0829_1458': 'メタモデルは単一,embeding MLP',\n",
       " '0901_1309': '全てのモデルを利用したメタモデルで予測',\n",
       " '0901_1311': '事前検証されたモデル選択、重みで予測値作成',\n",
       " '0901_1737': '自己学習：別のモデルの予測確率値による信頼度が大きなテスト領域データを学習に利用',\n",
       " '0901_1745': '事前学習による重みづけ、モデル選択',\n",
       " '0902_1006': 'tmp',\n",
       " '0902_2137': '反復擬似ラベル付与',\n",
       " '0902_2305': 'これまで実装した全モデルでスタッキ、メタ学習',\n",
       " '0902_2312': '事前学データでモデル選択'}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "90e1316d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0901_1311</th>\n",
       "      <th>0901_1737</th>\n",
       "      <th>0901_1745</th>\n",
       "      <th>0902_1006</th>\n",
       "      <th>0902_2137</th>\n",
       "      <th>0902_2305</th>\n",
       "      <th>0902_2312</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_00000</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_00001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_00002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_00003</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_00004</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0901_1311  0901_1737  0901_1745  0902_1006  0902_2137  0902_2305  \\\n",
       "0                                                                              \n",
       "test_00000          1          1          1          1          1          1   \n",
       "test_00001          0          0          0          0          0          0   \n",
       "test_00002          0          0          0          0          0          0   \n",
       "test_00003          1          1          1          1          1          1   \n",
       "test_00004          0          0          0          0          0          0   \n",
       "\n",
       "            0902_2312  \n",
       "0                      \n",
       "test_00000          1  \n",
       "test_00001          0  \n",
       "test_00002          0  \n",
       "test_00003          1  \n",
       "test_00004          0  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_date = [\n",
    "    \"0901_1311\", \"0901_1737\", \"0901_1745\", \"0902_1006\", \"0902_2137\", \"0902_2305\", \"0902_2312\"\n",
    "]\n",
    "\n",
    "pathes = [\n",
    "    f\"../output/99_Submision/{date}__submit.csv\" for date in select_date\n",
    "]\n",
    "\n",
    "df_merge = pd.DataFrame()\n",
    "for date, path in zip(\n",
    "    select_date, pathes\n",
    "):\n",
    "    df_tmp = pd.read_csv(path, index_col=0, header=None).rename(\n",
    "        {1: date}, axis=\"columns\"\n",
    "    )\n",
    "    df_merge = pd.concat(\n",
    "        [df_merge, df_tmp], axis=\"columns\"\n",
    "    )\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "796ceb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14268284 0.14322818 0.14343788 0.14233813 0.14256107 0.14267303\n",
      " 0.14307888]\n"
     ]
    }
   ],
   "source": [
    "weights = [\n",
    "    0.5995921142080217,\n",
    "    0.6018837583275902,\n",
    "    0.6027649769585253,\n",
    "    0.5981435363368803,\n",
    "    0.5990803915752002,\n",
    "    0.5995508982035928,\n",
    "    0.6012563565659587\n",
    "]\n",
    "weights = np.array(weights)\n",
    "weights = np.array(weights) / sum(weights)\n",
    "print(weights)\n",
    "\n",
    "df_merge_new = df_merge.dot(weights).round().astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c7f69020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0829_1453</th>\n",
       "      <th>0829_1458</th>\n",
       "      <th>0901_1311</th>\n",
       "      <th>0901_1737</th>\n",
       "      <th>0901_1745</th>\n",
       "      <th>0902_1006</th>\n",
       "      <th>0902_2137</th>\n",
       "      <th>0902_2305</th>\n",
       "      <th>0902_2312</th>\n",
       "      <th>final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0829_1453</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964363</td>\n",
       "      <td>0.890047</td>\n",
       "      <td>0.873122</td>\n",
       "      <td>0.860700</td>\n",
       "      <td>0.875143</td>\n",
       "      <td>0.874446</td>\n",
       "      <td>0.884301</td>\n",
       "      <td>0.871064</td>\n",
       "      <td>0.918881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0829_1458</th>\n",
       "      <td>0.964363</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.880436</td>\n",
       "      <td>0.863792</td>\n",
       "      <td>0.851929</td>\n",
       "      <td>0.866504</td>\n",
       "      <td>0.866241</td>\n",
       "      <td>0.877349</td>\n",
       "      <td>0.864134</td>\n",
       "      <td>0.910101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0901_1311</th>\n",
       "      <td>0.890047</td>\n",
       "      <td>0.880436</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.902359</td>\n",
       "      <td>0.888161</td>\n",
       "      <td>0.904672</td>\n",
       "      <td>0.910323</td>\n",
       "      <td>0.898494</td>\n",
       "      <td>0.878003</td>\n",
       "      <td>0.936430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0901_1737</th>\n",
       "      <td>0.873122</td>\n",
       "      <td>0.863792</td>\n",
       "      <td>0.902359</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967415</td>\n",
       "      <td>0.899188</td>\n",
       "      <td>0.895802</td>\n",
       "      <td>0.893067</td>\n",
       "      <td>0.875122</td>\n",
       "      <td>0.936037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0901_1745</th>\n",
       "      <td>0.860700</td>\n",
       "      <td>0.851929</td>\n",
       "      <td>0.888161</td>\n",
       "      <td>0.967415</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.886478</td>\n",
       "      <td>0.884829</td>\n",
       "      <td>0.882154</td>\n",
       "      <td>0.869011</td>\n",
       "      <td>0.922968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0902_1006</th>\n",
       "      <td>0.875143</td>\n",
       "      <td>0.866504</td>\n",
       "      <td>0.904672</td>\n",
       "      <td>0.899188</td>\n",
       "      <td>0.886478</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897460</td>\n",
       "      <td>0.892556</td>\n",
       "      <td>0.876260</td>\n",
       "      <td>0.926563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0902_2137</th>\n",
       "      <td>0.874446</td>\n",
       "      <td>0.866241</td>\n",
       "      <td>0.910323</td>\n",
       "      <td>0.895802</td>\n",
       "      <td>0.884829</td>\n",
       "      <td>0.897460</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.913376</td>\n",
       "      <td>0.895636</td>\n",
       "      <td>0.934011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0902_2305</th>\n",
       "      <td>0.884301</td>\n",
       "      <td>0.877349</td>\n",
       "      <td>0.898494</td>\n",
       "      <td>0.893067</td>\n",
       "      <td>0.882154</td>\n",
       "      <td>0.892556</td>\n",
       "      <td>0.913376</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967447</td>\n",
       "      <td>0.944279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0902_2312</th>\n",
       "      <td>0.871064</td>\n",
       "      <td>0.864134</td>\n",
       "      <td>0.878003</td>\n",
       "      <td>0.875122</td>\n",
       "      <td>0.869011</td>\n",
       "      <td>0.876260</td>\n",
       "      <td>0.895636</td>\n",
       "      <td>0.967447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.924408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final</th>\n",
       "      <td>0.918881</td>\n",
       "      <td>0.910101</td>\n",
       "      <td>0.936430</td>\n",
       "      <td>0.936037</td>\n",
       "      <td>0.922968</td>\n",
       "      <td>0.926563</td>\n",
       "      <td>0.934011</td>\n",
       "      <td>0.944279</td>\n",
       "      <td>0.924408</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0829_1453  0829_1458  0901_1311  0901_1737  0901_1745  0902_1006  \\\n",
       "0829_1453   1.000000   0.964363   0.890047   0.873122   0.860700   0.875143   \n",
       "0829_1458   0.964363   1.000000   0.880436   0.863792   0.851929   0.866504   \n",
       "0901_1311   0.890047   0.880436   1.000000   0.902359   0.888161   0.904672   \n",
       "0901_1737   0.873122   0.863792   0.902359   1.000000   0.967415   0.899188   \n",
       "0901_1745   0.860700   0.851929   0.888161   0.967415   1.000000   0.886478   \n",
       "0902_1006   0.875143   0.866504   0.904672   0.899188   0.886478   1.000000   \n",
       "0902_2137   0.874446   0.866241   0.910323   0.895802   0.884829   0.897460   \n",
       "0902_2305   0.884301   0.877349   0.898494   0.893067   0.882154   0.892556   \n",
       "0902_2312   0.871064   0.864134   0.878003   0.875122   0.869011   0.876260   \n",
       "final       0.918881   0.910101   0.936430   0.936037   0.922968   0.926563   \n",
       "\n",
       "           0902_2137  0902_2305  0902_2312     final  \n",
       "0829_1453   0.874446   0.884301   0.871064  0.918881  \n",
       "0829_1458   0.866241   0.877349   0.864134  0.910101  \n",
       "0901_1311   0.910323   0.898494   0.878003  0.936430  \n",
       "0901_1737   0.895802   0.893067   0.875122  0.936037  \n",
       "0901_1745   0.884829   0.882154   0.869011  0.922968  \n",
       "0902_1006   0.897460   0.892556   0.876260  0.926563  \n",
       "0902_2137   1.000000   0.913376   0.895636  0.934011  \n",
       "0902_2305   0.913376   1.000000   0.967447  0.944279  \n",
       "0902_2312   0.895636   0.967447   1.000000  0.924408  \n",
       "final       0.934011   0.944279   0.924408  1.000000  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge_cp = df_merge.copy()\n",
    "df_merge_cp[\"final\"] = df_merge_new.values\n",
    "df_merge_cp.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "63a6c936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "test_00000    1\n",
       "test_00001    0\n",
       "test_00002    0\n",
       "test_00003    1\n",
       "test_00004    0\n",
       "             ..\n",
       "test_32434    1\n",
       "test_32435    1\n",
       "test_32436    1\n",
       "test_32437    0\n",
       "test_32438    0\n",
       "Length: 32439, dtype: int64"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "33ab7fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_new.to_csv(\"../output/99_Submision/0902_2340__submit.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98b4977b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6051754246705826\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 重みを二乗して、いい感じのやつほど強調されるように\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "w = np.array(list(scores.values()))\n",
    "plt.plot(w)\n",
    "\n",
    "w = w**2\n",
    "plt.plot(w)\n",
    "X_weighted = X.dot(w/sum(w))\n",
    "\n",
    "print(f1_score(\n",
    "    (X_weighted>0.5).astype(int), y\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ad90d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "## テスト予測値のうち、確信度が大きなデータをtrainデータに加えて、新規データを作成する\n",
    "\n",
    "class F01_tmp():\n",
    "    def __init__(self):\n",
    "        self.threshold_pos = 0.75\n",
    "        self.threshold_neg = 0.10\n",
    "\n",
    "    def f01__get__data(self, data_train=None, data_test=None):\n",
    "        self.data_submit = pd.read_csv(\"../output/07__Stack/03__Ensemble/0901_1240/model_level_probas_is_submit.csv\", index_col=0)\n",
    "\n",
    "        if isinstance(data_train, pd.DataFrame):\n",
    "            self.data_train = data_train\n",
    "        else:\n",
    "            self.data_train = pd.read_csv(\"../output/05__01__SentenceTransformer_Raw/train.csv\")\n",
    "        if isinstance(data_test, pd.DataFrame):\n",
    "            self.data_test = data_test\n",
    "        else:\n",
    "            self.data_test = pd.read_csv(\"../output/05__01__SentenceTransformer_Raw/test.csv\")\n",
    "\n",
    "    def f02__get_shift(self, data_submit_mean=None):\n",
    "        if isinstance(data_submit_mean, pd.Series):\n",
    "            pass\n",
    "        else:\n",
    "            data_submit_mean = self.data_submit.mean(axis=1)\n",
    "\n",
    "        data_shift = data_submit_mean[np.logical_or(\n",
    "            data_submit_mean < self.threshold_neg,\n",
    "            data_submit_mean > self.threshold_pos\n",
    "        )]\n",
    "\n",
    "        self.shift_index = data_shift.index\n",
    "        self.shift_label = (data_shift>0.5).astype(int)\n",
    "\n",
    "        self.data_test_shift = self.data_test.iloc[self.shift_index]\n",
    "        self.data_test_shift.loc[:, \"final_status\"] = self.shift_label.values\n",
    "\n",
    "    def f03__save(self):\n",
    "        self.data_train_shift = pd.concat(\n",
    "            [self.data_train, self.data_test_shift], axis=\"index\"\n",
    "        ).reset_index(drop=True)\n",
    "        # self.data_train.to_csv(\"../output/10__ShiftTest/train.csv\")\n",
    "        return self.data_train_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca79a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/henmi_note/Desktop/signate2/output/05__01__SentenceTransformer_Raw/train.csv\",)\n",
    "\n",
    "from sklearn.model_selection import  train_test_split\n",
    "X = data.drop(\"final_status\", axis=\"columns\")\n",
    "y = data[\"final_status\"]\n",
    "dataset = {\n",
    "    k: data for k, data in zip(\n",
    "        [\"X_train\", \"X_val\", \"y_train\", \"y_val\"], train_test_split(X, y, stratify=y)\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd2e8b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"final_status\"\n",
    "data_train, data_val_test = train_test_split(data, test_size=0.4, stratify=data[target_col])\n",
    "data_val, data_test = train_test_split(data_val_test, test_size=0.5, stratify=data_val_test[target_col])\n",
    "y_val = data_val[\"final_status\"]\n",
    "X_val = data_val.drop(\"final_status\", axis=\"columns\")\n",
    "y_test = data_test[\"final_status\"]\n",
    "X_test = data_test.drop(\"final_status\", axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56487f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline]  VAL  F1=0.5763, AUC=0.7532\n",
      "[Baseline]  TEST F1=0.5732, AUC=0.7523\n",
      "[SelfTrain step 1] val_f1=0.5763, pick_pos=1051, pick_neg=1020, pick_total=2071\n",
      "[SelfTrain step 2] val_f1=0.5804, pick_pos=521, pick_neg=73, pick_total=594\n",
      "[SelfTrain step 3] val_f1=0.5707, pick_pos=293, pick_neg=31, pick_total=324\n",
      "[SelfTrain step 4] val_f1=0.5702, pick_pos=211, pick_neg=36, pick_total=247\n",
      "[SelfTrain] early stop by patience at step 4\n",
      "[SelfTrain] VAL  F1=0.5702, AUC=0.7523\n",
      "[SelfTrain] TEST F1=0.5733, AUC=0.7529\n",
      "\n",
      "=== COMPARISON (Test set) ===\n",
      "Baseline : F1=0.5732, AUC=0.7523, Prec=0.4955, Rec=0.6800\n",
      "SelfTrain: F1=0.5733, AUC=0.7529, Prec=0.5021, Rec=0.6680\n"
     ]
    }
   ],
   "source": [
    "    # --- 擬似ラベル作成（0/1 に丸め） ---\n",
    "    pseudo_X = pool.iloc[take_idx].copy()\n",
    "    pseudo_y = (proba_pool[take_idx] >= 0.5).astype(int)\n",
    "    pseudo_df = pseudo_X.copy()\n",
    "    pseudo_df[TARGET] = pseudo_y\n",
    "\n",
    "    # ======== 擬似ラベルの正しさを検証 ========\n",
    "    # もし pool が「ラベルを隠しただけの既知データ」であれば\n",
    "    # 元の data_val (正解ラベル付き) と比較できる\n",
    "    true_labels = data_val.iloc[take_idx][TARGET]   # 真のラベル\n",
    "    f1_pseudo = f1_score(true_labels, pseudo_y)    # 擬似ラベル vs 正解\n",
    "    print(f\"[SelfTrain step {step}] pseudo-label F1={f1_pseudo:.4f}\")\n",
    "\n",
    "    # --- 学習集合に追加 & プールから除去 ---\n",
    "    train_df = pd.concat([train_df, pseudo_df], axis=0, ignore_index=True)\n",
    "    pool = pool.drop(pool.index[take_idx]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c27c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[867, 881, 892, 918, 932]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 確信度と正解率に相関はある？？\n",
    "model = LGBMClassifier(**params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360db8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "0be526b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5695553500882575\n"
     ]
    }
   ],
   "source": [
    "# モデル再学習\n",
    "from lightgbm import LGBMClassifier\n",
    "params = {\n",
    "        \"n_estimators\": 200,\n",
    "        \"num_leaves\": 32,\n",
    "        \"boosting_type\": \"dart\",\n",
    "        \"reg_alpha\": 10,\n",
    "        \"reg_lambda\": 0,\n",
    "        \"max_depth\": 10,\n",
    "        \"drop_seed\": 42,\n",
    "        \"is_unbalance\": True,\n",
    "        \"verbosity\": -1\n",
    "      }\n",
    "model = LGBMClassifier(**params)\n",
    "target_col = \"final_status\"\n",
    "X, y = data_train_shift.drop(target_col, axis=\"columns\"), data_train_shift[target_col]\n",
    "model.fit(X, y)\n",
    "y_pred_after_shift = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "print(\n",
    "    f1_score(y_pred_after_shift, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "ecfc7ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LightGBM_tmp_1__proba_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.386713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.118321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.520234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.365362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.521869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60547</th>\n",
       "      <td>60547</td>\n",
       "      <td>0.477195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60548</th>\n",
       "      <td>60548</td>\n",
       "      <td>0.452433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60549</th>\n",
       "      <td>60549</td>\n",
       "      <td>0.489123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60550</th>\n",
       "      <td>60550</td>\n",
       "      <td>0.514921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60551</th>\n",
       "      <td>60551</td>\n",
       "      <td>0.338487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60552 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  LightGBM_tmp_1__proba_pos\n",
       "0               0                   0.386713\n",
       "1               1                   0.118321\n",
       "2               2                   0.520234\n",
       "3               3                   0.365362\n",
       "4               4                   0.521869\n",
       "...           ...                        ...\n",
       "60547       60547                   0.477195\n",
       "60548       60548                   0.452433\n",
       "60549       60549                   0.489123\n",
       "60550       60550                   0.514921\n",
       "60551       60551                   0.338487\n",
       "\n",
       "[60552 rows x 2 columns]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"/Users/henmi_note/Desktop/signate2/output/07__Stack/02__MetaFeats_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d68288cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline]  VAL  F1=0.5763, AUC=0.7532\n",
      "[Baseline]  TEST F1=0.5732, AUC=0.7523\n",
      "[SelfTrain step 1] val_f1=0.5763, pick_pos=416, pick_neg=1020, pick_total=1436, pseudo-label F1=0.8665\n",
      "[SelfTrain step 2] val_f1=0.5727, pick_pos=39, pick_neg=46, pick_total=85, pseudo-label F1=0.9600\n",
      "[SelfTrain step 3] val_f1=0.5751, pick_pos=1, pick_neg=5, pick_total=6, pseudo-label F1=0.0000\n",
      "[SelfTrain] early stop by patience at step 3\n",
      "[SelfTrain] VAL  F1=0.5751, AUC=0.7509\n",
      "[SelfTrain] TEST F1=0.5807, AUC=0.7511\n",
      "\n",
      "=== COMPARISON (Test set) ===\n",
      "Baseline : F1=0.5732, AUC=0.7523, Prec=0.4955, Rec=0.6800\n",
      "SelfTrain: F1=0.5807, AUC=0.7511, Prec=0.5020, Rec=0.6889\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_recall_fscore_support\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# =========================================================\n",
    "# 設定\n",
    "# =========================================================\n",
    "TARGET = \"final_status\"\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# 擬似ラベルの確信度しきい値\n",
    "TH_POS = [0.75, 0.8, 0.85, 0.9, 0.95]      # Positive とみなす下限\n",
    "TH_NEG = 0.05      # Negative とみなす上限\n",
    "NEG_POS_RATIO = 5 # ネガポジ比率\n",
    "\n",
    "# 学習時の二値化しきい値（評価用）\n",
    "THRESH_PRED = 0.5\n",
    "\n",
    "# 反復回数と早期停止\n",
    "MAX_STEPS = 5\n",
    "PATIENCE = 2  # 検証F1が改善しない反復が続いたら停止\n",
    "\n",
    "# LGBM ハイパーパラメータ\n",
    "lgbm_params = dict(\n",
    "    n_estimators=200,\n",
    "    num_leaves=32,\n",
    "    boosting_type=\"gbdt\",  # まずは安定な gbdt\n",
    "    reg_alpha=10,\n",
    "    reg_lambda=0,\n",
    "    max_depth=10,\n",
    "    is_unbalance=True,\n",
    "    random_state=RANDOM_STATE,\n",
    "    verbosity=-1,\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# データ分割: train / val / pool / test\n",
    "#   - pool は未ラベル集合を想定（ここでは例として val のコピーを使用し、答え合わせ用に真ラベルも保持）\n",
    "# =========================================================\n",
    "# data は TARGET を含む DataFrame を前提\n",
    "data_tr, data_tmp = train_test_split(\n",
    "    data, test_size=0.4, stratify=data[TARGET], random_state=RANDOM_STATE\n",
    ")\n",
    "data_val, data_te = train_test_split(\n",
    "    data_tmp, test_size=0.5, stratify=data_tmp[TARGET], random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "X_val = data_val.drop(columns=[TARGET]).copy()\n",
    "y_val = data_val[TARGET].copy()\n",
    "\n",
    "X_test = data_te.drop(columns=[TARGET]).copy()\n",
    "y_test = data_te[TARGET].copy()\n",
    "\n",
    "# 「未ラベルプール」：特徴量のみ（学習に使う用）\n",
    "pool = data_val.drop(columns=[TARGET]).copy()\n",
    "# 「答え合わせ用プール」：真のラベルつき（F1計測用、検証用セットとは独立コピー）\n",
    "pool_full = data_val.copy()\n",
    "\n",
    "# =========================================================\n",
    "# ① ベースライン（擬似ラベルなし）\n",
    "# =========================================================\n",
    "baseline_tr = data_tr.copy()\n",
    "Xb, yb = baseline_tr.drop(columns=[TARGET]), baseline_tr[TARGET]\n",
    "\n",
    "baseline_model = LGBMClassifier(**lgbm_params)\n",
    "baseline_model.fit(Xb, yb)\n",
    "\n",
    "# 検証\n",
    "val_proba_base = baseline_model.predict_proba(X_val)[:, 1]\n",
    "val_pred_base = (val_proba_base >= THRESH_PRED).astype(int)\n",
    "val_f1_base = f1_score(y_val, val_pred_base)\n",
    "val_auc_base = roc_auc_score(y_val, val_proba_base)\n",
    "\n",
    "# テスト\n",
    "test_proba_base = baseline_model.predict_proba(X_test)[:, 1]\n",
    "test_pred_base = (test_proba_base >= THRESH_PRED).astype(int)\n",
    "test_f1_base = f1_score(y_test, test_pred_base)\n",
    "test_auc_base = roc_auc_score(y_test, test_proba_base)\n",
    "\n",
    "print(f\"[Baseline]  VAL  F1={val_f1_base:.4f}, AUC={val_auc_base:.4f}\")\n",
    "print(f\"[Baseline]  TEST F1={test_f1_base:.4f}, AUC={test_auc_base:.4f}\")\n",
    "\n",
    "# =========================================================\n",
    "# ② 自己学習（擬似ラベル追加）\n",
    "#   条件: negative の件数は positive の 2 倍以下に制限\n",
    "#   かつ、各ステップで擬似ラベルの F1（真ラベルと比較）を出力\n",
    "# =========================================================\n",
    "train_df = data_tr.copy()\n",
    "\n",
    "best_val_f1 = -np.inf\n",
    "no_improve_rounds = 0\n",
    "\n",
    "for step in range(1, MAX_STEPS + 1):\n",
    "    # --- 学習 ---\n",
    "    model = LGBMClassifier(**lgbm_params)\n",
    "    Xtr, ytr = train_df.drop(columns=[TARGET]), train_df[TARGET]\n",
    "    model.fit(Xtr, ytr)\n",
    "\n",
    "    # --- 検証スコア ---\n",
    "    proba_val = model.predict_proba(X_val)[:, 1]\n",
    "    pred_val = (proba_val >= THRESH_PRED).astype(int)\n",
    "    val_f1 = f1_score(y_val, pred_val)\n",
    "\n",
    "    # --- 未ラベルプールが空なら停止 ---\n",
    "    if len(pool) == 0:\n",
    "        print(f\"[SelfTrain step {step}] pool empty → stop\")\n",
    "        break\n",
    "\n",
    "    # --- プールの確率 ---\n",
    "    proba_pool = model.predict_proba(pool)[:, 1]\n",
    "\n",
    "    # 高信頼 Positive / Negative 候補\n",
    "    mask_pos = proba_pool >= TH_POS[step]\n",
    "    mask_neg = proba_pool <= TH_NEG\n",
    "\n",
    "    pos_idx = np.where(mask_pos)[0]\n",
    "    neg_idx = np.where(mask_neg)[0]\n",
    "\n",
    "    # ===== 件数制限 =====\n",
    "    # negative の件数は positive の 2 倍以下\n",
    "    n_pos = len(pos_idx)\n",
    "    if n_pos == 0:\n",
    "        # positive が 0 件なら negative も 0（= 追加しない）\n",
    "        neg_idx = np.array([], dtype=int)\n",
    "    else:\n",
    "        n_neg_allowed = NEG_POS_RATIO * n_pos\n",
    "        if len(neg_idx) > n_neg_allowed:\n",
    "            # 負例は確信度がより高い順（proba が低い順）に選別\n",
    "            neg_sorted = neg_idx[np.argsort(proba_pool[neg_idx])]  # 低い順\n",
    "            neg_idx = neg_sorted[:n_neg_allowed]\n",
    "\n",
    "    take_idx = np.concatenate([pos_idx, neg_idx])\n",
    "\n",
    "    # --- 取り込むサンプルがない場合は停止 ---\n",
    "    if len(take_idx) == 0:\n",
    "        print(\n",
    "            f\"[SelfTrain step {step}] val_f1={val_f1:.4f}, pick_pos=0, pick_neg=0, pick_total=0 → stop\"\n",
    "        )\n",
    "        break\n",
    "\n",
    "    # --- 擬似ラベル作成（0/1 に丸め） ---\n",
    "    pseudo_X = pool.iloc[take_idx].copy()\n",
    "    pseudo_y = (proba_pool[take_idx] >= 0.5).astype(int)\n",
    "\n",
    "    # ======== 擬似ラベルの正しさを検証（pool_full の真ラベルで答え合わせ） ========\n",
    "    true_labels = pool_full.iloc[take_idx][TARGET].values\n",
    "    f1_pseudo = f1_score(true_labels, pseudo_y)\n",
    "    print(\n",
    "        f\"[SelfTrain step {step}] val_f1={val_f1:.4f}, \"\n",
    "        f\"pick_pos={len(pos_idx)}, pick_neg={len(neg_idx)}, pick_total={len(take_idx)}, \"\n",
    "        f\"pseudo-label F1={f1_pseudo:.4f}\"\n",
    "    )\n",
    "\n",
    "    # --- 早期停止（検証F1） ---\n",
    "    if val_f1 > best_val_f1 + 1e-6:\n",
    "        best_val_f1 = val_f1\n",
    "        no_improve_rounds = 0\n",
    "    else:\n",
    "        no_improve_rounds += 1\n",
    "        if no_improve_rounds >= PATIENCE:\n",
    "            print(f\"[SelfTrain] early stop by patience at step {step}\")\n",
    "            # 早期停止するが、このステップの pickup は追加しないまま終了\n",
    "            break\n",
    "\n",
    "    # --- 学習集合に追加 ---\n",
    "    pseudo_df = pseudo_X.copy()\n",
    "    pseudo_df[TARGET] = pseudo_y\n",
    "    train_df = pd.concat([train_df, pseudo_df], axis=0, ignore_index=True)\n",
    "\n",
    "    # --- プールから除去（特徴量/真ラベルの両方を同期させて削除） ---\n",
    "    pool = pool.drop(pool.index[take_idx]).reset_index(drop=True)\n",
    "    pool_full = pool_full.drop(pool_full.index[take_idx]).reset_index(drop=True)\n",
    "\n",
    "# --- 反復後の最終学習 ---\n",
    "final_model = LGBMClassifier(**lgbm_params)\n",
    "Xtr_f, ytr_f = train_df.drop(columns=[TARGET]), train_df[TARGET]\n",
    "final_model.fit(Xtr_f, ytr_f)\n",
    "\n",
    "# --- 検証スコア ---\n",
    "val_proba_final = final_model.predict_proba(X_val)[:, 1]\n",
    "val_pred_final = (val_proba_final >= THRESH_PRED).astype(int)\n",
    "val_f1_final = f1_score(y_val, val_pred_final)\n",
    "val_auc_final = roc_auc_score(y_val, val_proba_final)\n",
    "\n",
    "# --- テストスコア ---\n",
    "test_proba_final = final_model.predict_proba(X_test)[:, 1]\n",
    "test_pred_final = (test_proba_final >= THRESH_PRED).astype(int)\n",
    "test_f1_final = f1_score(y_test, test_pred_final)\n",
    "test_auc_final = roc_auc_score(y_test, test_proba_final)\n",
    "\n",
    "# 追加で詳細指標（適合率/再現率/F1）を確認\n",
    "prec_base, rec_base, f1_base, _ = precision_recall_fscore_support(\n",
    "    y_test, test_pred_base, average=\"binary\", zero_division=0\n",
    ")\n",
    "prec_self, rec_self, f1_self, _ = precision_recall_fscore_support(\n",
    "    y_test, test_pred_final, average=\"binary\", zero_division=0\n",
    ")\n",
    "\n",
    "print(f\"[SelfTrain] VAL  F1={val_f1_final:.4f}, AUC={val_auc_final:.4f}\")\n",
    "print(f\"[SelfTrain] TEST F1={test_f1_final:.4f}, AUC={test_auc_final:.4f}\")\n",
    "\n",
    "print(\"\\n=== COMPARISON (Test set) ===\")\n",
    "print(f\"Baseline : F1={test_f1_base:.4f}, AUC={test_auc_base:.4f}, \"\n",
    "      f\"Prec={prec_base:.4f}, Rec={rec_base:.4f}\")\n",
    "print(f\"SelfTrain: F1={test_f1_final:.4f}, AUC={test_auc_final:.4f}, \"\n",
    "      f\"Prec={prec_self:.4f}, Rec={rec_self:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f5430ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cv = pd.read_csv(\"../output/05__SentenceTransformer/train.csv\")\n",
    "data_test = pd.read_csv(\"../output/05__SentenceTransformer/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "09e47c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0.1, 0.51, 0.6]).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d720997e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 score: 0.5737402841061378 cnt: 0\n",
      "add data num: 1020\n",
      "step 1 score: 0.5746933399193216 cnt: 0\n",
      "add data num: 1035\n",
      "step 2 score: 0.5761548064918851 cnt: 0\n",
      "add data num: 1035\n",
      "step 3 score: 0.5761548064918851 cnt: 1\n",
      "add data num: 1035\n"
     ]
    }
   ],
   "source": [
    "# データ整理: CVデータとtestデータ\n",
    "target_col = \"final_status\"\n",
    "NEG_POS_RATIO = 4\n",
    "threshold_pos = 0.8\n",
    "threshold_neg = 0.1\n",
    "PATIENCE = 2\n",
    "NUM_STEPS = 10\n",
    "\n",
    "# モデル設定など\n",
    "params = dict(\n",
    "    n_estimators=200,\n",
    "    num_leaves=31,\n",
    "    boosting_type=\"gbdt\",\n",
    "    max_depth=-1,\n",
    "    learning_rate=0.05,\n",
    "    reg_alpha=0.0,\n",
    "    reg_lambda=0.0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    is_unbalance=True,\n",
    "    random_state=RANDOM_STATE,\n",
    "    verbosity=-1,\n",
    ")\n",
    "\n",
    "score_old = 0\n",
    "cnt = 0\n",
    "cnt_len_data_add = 0\n",
    "\n",
    "# ループ開始\n",
    "## CVループ\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "is_add = pd.Series([False]*len(data_test))\n",
    "data_add = pd.DataFrame()\n",
    "len_data_add_old = 0\n",
    "\n",
    "def split_X_y(data):\n",
    "    return data.drop(target_col, axis=\"columns\"), data[target_col]\n",
    "\n",
    "for step in range(NUM_STEPS):\n",
    "    y_cv_pred_proba = np.zeros(len(data_cv))\n",
    "    y_test_pred_proba = np.zeros((len(data_test), 3))\n",
    "    ### cv -> train, val\n",
    "    X_cv, y_cv = split_X_y(data_cv)\n",
    "    for i, (idx_train, idx_val) in enumerate(cv.split(X_cv, y_cv)):\n",
    "    ### trainに擬似ラベルデータ追加\n",
    "        data_train = data_cv.iloc[idx_train]\n",
    "        data_val = data_cv.iloc[idx_val]\n",
    "        data_train_with_giji = pd.concat(\n",
    "            [data_train, data_add], axis=\"index\"\n",
    "        ).reset_index(drop=True)\n",
    "        X_train, y_train = split_X_y(data_train_with_giji)\n",
    "    ### trainで学習\n",
    "        model = LGBMClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "    ### val を予測、評価\n",
    "        X_val, y_val = split_X_y(data_val)\n",
    "        y_cv_pred_proba[idx_val] = model.predict_proba(X_val)[:, 1]\n",
    "    ### test を予測、評価\n",
    "        X_test, _ = split_X_y(data_test)\n",
    "        y_test_pred_proba[:, i] = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    ## cv評価\n",
    "    score_new = f1_score(\n",
    "        y_cv, y_cv_pred_proba.round()\n",
    "    )\n",
    "    if score_new <= score_old:\n",
    "        cnt += 1\n",
    "    else:\n",
    "        cnt = 0\n",
    "    print(f\"step {step} score: {score_new} cnt: {cnt}\")\n",
    "    if cnt >= PATIENCE:\n",
    "        print(\"--- Break ---\")\n",
    "        break\n",
    "\n",
    "    else:\n",
    "        score_old = score_new\n",
    "        ## testのうち、まだ追加していない、かつ確信度の大きな行を抽出\n",
    "        y_test_pred_proba_meaned = y_test_pred_proba.mean(axis=1)\n",
    "        data_add_pos = data_test[np.logical_and(\n",
    "            y_test_pred_proba_meaned > threshold_pos*(1.01**step),\n",
    "            is_add.apply(lambda x: not x)\n",
    "        )]\n",
    "        data_add_neg = data_test[np.logical_and(\n",
    "            y_test_pred_proba_meaned < threshold_neg,\n",
    "            is_add.apply(lambda x: not x)\n",
    "        )]\n",
    "        ### data_add_neg の件数調整\n",
    "        if len(data_add_neg) > NEG_POS_RATIO*len(data_add_pos):\n",
    "            data_add_neg = data_add_neg.iloc[\n",
    "                y_test_pred_proba_meaned[\n",
    "                    np.logical_and(\n",
    "                        y_test_pred_proba_meaned < threshold_neg,\n",
    "                        is_add.apply(lambda x: not x)\n",
    "                    )\n",
    "                ].argsort()[:len(data_add_pos)*NEG_POS_RATIO]\n",
    "            ]\n",
    "        data_add = pd.concat(\n",
    "            [data_add, data_add_pos], axis=\"index\"\n",
    "        )\n",
    "        data_add = pd.concat(\n",
    "            [data_add, data_add_neg], axis=\"index\"\n",
    "        )\n",
    "        is_add.iloc[data_add.index] = [True]*len(data_add)\n",
    "        print(f\"add data num: {len(data_add)}\")\n",
    "        if len_data_add_old == len(data_add):\n",
    "            cnt_len_data_add += 1\n",
    "        else:\n",
    "            cnt_len_data_add = 0\n",
    "        if cnt_len_data_add == 2:\n",
    "            break\n",
    "        else:\n",
    "            len_data_add_old = len(data_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adb223e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3243424b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 score: 0.5755231876778838 cnt: 0\n",
      "add data num: 1010\n",
      "step 1 score: 0.5763197313624467 cnt: 0\n",
      "add data num: 1010\n",
      "step 2 score: 0.5763197313624467 cnt: 1\n",
      "add data num: 1010\n"
     ]
    }
   ],
   "source": [
    "# データ整理: CVデータとtestデータ\n",
    "target_col = \"final_status\"\n",
    "NEG_POS_RATIO = 4\n",
    "threshold_pos = 0.8\n",
    "threshold_neg = 0.1\n",
    "PATIENCE = 2\n",
    "NUM_STEPS = 10\n",
    "\n",
    "# モデル設定など\n",
    "params = dict(\n",
    "    n_estimators=200,\n",
    "    num_leaves=31,\n",
    "    boosting_type=\"gbdt\",\n",
    "    max_depth=-1,\n",
    "    learning_rate=0.05,\n",
    "    reg_alpha=0.0,\n",
    "    reg_lambda=0.0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    is_unbalance=True,\n",
    "    # random_state=RANDOM_STATE,\n",
    "    verbosity=-1,\n",
    ")\n",
    "\n",
    "score_old = 0\n",
    "cnt = 0\n",
    "cnt_len_data_add = 0\n",
    "\n",
    "# ループ開始\n",
    "## CVループ\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "is_add = pd.Series([False]*len(data_test))\n",
    "data_add = pd.DataFrame()\n",
    "len_data_add_old = 0\n",
    "\n",
    "def split_X_y(data):\n",
    "    return data.drop(target_col, axis=\"columns\"), data[target_col]\n",
    "\n",
    "for step in range(NUM_STEPS):\n",
    "    y_cv_pred_proba = np.zeros(len(data_cv))\n",
    "    y_test_pred_proba = np.zeros((len(data_test), 3))\n",
    "    ### cv -> train, val\n",
    "    X_cv, y_cv = split_X_y(data_cv)\n",
    "    for i, (idx_train, idx_val) in enumerate(cv.split(X_cv, y_cv)):\n",
    "    ### trainに擬似ラベルデータ追加\n",
    "        data_train = data_cv.iloc[idx_train]\n",
    "        data_val = data_cv.iloc[idx_val]\n",
    "        data_train_with_giji = pd.concat(\n",
    "            [data_train, data_add], axis=\"index\"\n",
    "        ).reset_index(drop=True)\n",
    "        X_train, y_train = split_X_y(data_train_with_giji)\n",
    "    ### trainで学習\n",
    "        # model = LGBMClassifier(**params)\n",
    "        ## 多数決分類器\n",
    "        from sklearn.ensemble import VotingClassifier\n",
    "        clf1 = LGBMClassifier(**params, random_state=41)\n",
    "        clf2 = LGBMClassifier(**params, random_state=42)\n",
    "        model = VotingClassifier(\n",
    "            estimators=[\n",
    "                (\"clf1\", clf1), (\"clf2\", clf2),\n",
    "            ],  voting = \"soft\"\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "    ### val を予測、評価\n",
    "        X_val, y_val = split_X_y(data_val)\n",
    "        y_cv_pred_proba[idx_val] = model.predict_proba(X_val)[:, 1]\n",
    "    ### test を予測、評価\n",
    "        X_test, _ = split_X_y(data_test)\n",
    "        y_test_pred_proba[:, i] = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    ## cv評価\n",
    "    score_new = f1_score(\n",
    "        y_cv, y_cv_pred_proba.round()\n",
    "    )\n",
    "    if score_new <= score_old:\n",
    "        cnt += 1\n",
    "    else:\n",
    "        cnt = 0\n",
    "    print(f\"step {step} score: {score_new} cnt: {cnt}\")\n",
    "    if cnt >= PATIENCE:\n",
    "        print(\"--- Break ---\")\n",
    "        break\n",
    "\n",
    "    else:\n",
    "        score_old = score_new\n",
    "        ## testのうち、まだ追加していない、かつ確信度の大きな行を抽出\n",
    "        y_test_pred_proba_meaned = y_test_pred_proba.mean(axis=1)\n",
    "        data_add_pos = data_test[np.logical_and(\n",
    "            y_test_pred_proba_meaned > threshold_pos*(1.01**step),\n",
    "            is_add.apply(lambda x: not x)\n",
    "        )]\n",
    "        data_add_neg = data_test[np.logical_and(\n",
    "            y_test_pred_proba_meaned < threshold_neg,\n",
    "            is_add.apply(lambda x: not x)\n",
    "        )]\n",
    "        ### data_add_neg の件数調整\n",
    "        if len(data_add_neg) > NEG_POS_RATIO*len(data_add_pos):\n",
    "            data_add_neg = data_add_neg.iloc[\n",
    "                y_test_pred_proba_meaned[\n",
    "                    np.logical_and(\n",
    "                        y_test_pred_proba_meaned < threshold_neg,\n",
    "                        is_add.apply(lambda x: not x)\n",
    "                    )\n",
    "                ].argsort()[:len(data_add_pos)*NEG_POS_RATIO]\n",
    "            ]\n",
    "        data_add = pd.concat(\n",
    "            [data_add, data_add_pos], axis=\"index\"\n",
    "        )\n",
    "        data_add = pd.concat(\n",
    "            [data_add, data_add_neg], axis=\"index\"\n",
    "        )\n",
    "        is_add.iloc[data_add.index] = [True]*len(data_add)\n",
    "        print(f\"add data num: {len(data_add)}\")\n",
    "        if len_data_add_old == len(data_add):\n",
    "            cnt_len_data_add += 1\n",
    "        else:\n",
    "            cnt_len_data_add = 0\n",
    "        if cnt_len_data_add == 2:\n",
    "            break\n",
    "        else:\n",
    "            len_data_add_old = len(data_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4c720ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>final_status</th>\n",
       "      <th>f01__goal</th>\n",
       "      <th>f04__after_Jul2014</th>\n",
       "      <th>f04__YearQuarter_2009Q2</th>\n",
       "      <th>f04__YearQuarter_2009Q3</th>\n",
       "      <th>f04__YearQuarter_2009Q4</th>\n",
       "      <th>f04__YearQuarter_2010Q1</th>\n",
       "      <th>f04__YearQuarter_2010Q2</th>\n",
       "      <th>f04__YearQuarter_2010Q3</th>\n",
       "      <th>f04__YearQuarter_2010Q4</th>\n",
       "      <th>...</th>\n",
       "      <th>f06__PC375__sentencePC</th>\n",
       "      <th>f06__PC376__sentencePC</th>\n",
       "      <th>f06__PC377__sentencePC</th>\n",
       "      <th>f06__PC378__sentencePC</th>\n",
       "      <th>f06__PC379__sentencePC</th>\n",
       "      <th>f06__PC380__sentencePC</th>\n",
       "      <th>f06__PC381__sentencePC</th>\n",
       "      <th>f06__PC382__sentencePC</th>\n",
       "      <th>f06__PC383__sentencePC</th>\n",
       "      <th>f06__PC384__sentencePC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>10.308986</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>0.005472</td>\n",
       "      <td>-0.000529</td>\n",
       "      <td>-0.002469</td>\n",
       "      <td>0.007676</td>\n",
       "      <td>-0.003253</td>\n",
       "      <td>-0.005858</td>\n",
       "      <td>-3.012657e-09</td>\n",
       "      <td>-4.204647e-12</td>\n",
       "      <td>-3.546401e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0</td>\n",
       "      <td>6.908755</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008241</td>\n",
       "      <td>-0.005321</td>\n",
       "      <td>0.007848</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>-0.003131</td>\n",
       "      <td>-0.005485</td>\n",
       "      <td>-1.902775e-09</td>\n",
       "      <td>-2.655699e-12</td>\n",
       "      <td>3.798711e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>0</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009183</td>\n",
       "      <td>-0.009091</td>\n",
       "      <td>-0.000953</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>-0.000773</td>\n",
       "      <td>0.007736</td>\n",
       "      <td>-0.003252</td>\n",
       "      <td>-5.481304e-10</td>\n",
       "      <td>-7.649645e-13</td>\n",
       "      <td>5.246079e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001648</td>\n",
       "      <td>-0.007339</td>\n",
       "      <td>-0.001597</td>\n",
       "      <td>-0.003089</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>-0.006445</td>\n",
       "      <td>-0.002330</td>\n",
       "      <td>6.281340e-10</td>\n",
       "      <td>8.766529e-13</td>\n",
       "      <td>-1.106065e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>0</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001775</td>\n",
       "      <td>-0.000978</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>-0.005342</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.008175</td>\n",
       "      <td>0.004072</td>\n",
       "      <td>7.977743e-10</td>\n",
       "      <td>1.113446e-12</td>\n",
       "      <td>-8.206238e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16604</th>\n",
       "      <td>0</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011808</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>-0.006971</td>\n",
       "      <td>-0.009105</td>\n",
       "      <td>0.010054</td>\n",
       "      <td>0.006768</td>\n",
       "      <td>-0.005730</td>\n",
       "      <td>3.752191e-09</td>\n",
       "      <td>5.236717e-12</td>\n",
       "      <td>-4.937998e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24055</th>\n",
       "      <td>0</td>\n",
       "      <td>6.650926</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011570</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>-0.008945</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>-0.006621</td>\n",
       "      <td>0.002190</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>-1.916849e-10</td>\n",
       "      <td>-2.674701e-13</td>\n",
       "      <td>-6.110285e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>0</td>\n",
       "      <td>8.517393</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006663</td>\n",
       "      <td>0.008468</td>\n",
       "      <td>-0.009823</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>-0.002737</td>\n",
       "      <td>-0.004764</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>7.248513e-10</td>\n",
       "      <td>1.011660e-12</td>\n",
       "      <td>1.834344e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23395</th>\n",
       "      <td>0</td>\n",
       "      <td>7.496097</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000367</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.011803</td>\n",
       "      <td>0.017459</td>\n",
       "      <td>-0.010777</td>\n",
       "      <td>-0.003733</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>-2.222395e-09</td>\n",
       "      <td>-3.101696e-12</td>\n",
       "      <td>2.421495e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201</th>\n",
       "      <td>0</td>\n",
       "      <td>10.714440</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007115</td>\n",
       "      <td>0.023709</td>\n",
       "      <td>0.006816</td>\n",
       "      <td>-0.001531</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>-0.008791</td>\n",
       "      <td>0.012106</td>\n",
       "      <td>1.727008e-09</td>\n",
       "      <td>2.410180e-12</td>\n",
       "      <td>8.373799e-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1010 rows × 436 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       final_status  f01__goal  f04__after_Jul2014  f04__YearQuarter_2009Q2  \\\n",
       "6                 0  10.308986                   1                    False   \n",
       "185               0   6.908755                   0                    False   \n",
       "372               0   4.615121                   0                    False   \n",
       "559               0   4.615121                   0                    False   \n",
       "584               0   3.931826                   0                    False   \n",
       "...             ...        ...                 ...                      ...   \n",
       "16604             0   2.708050                   1                    False   \n",
       "24055             0   6.650926                   1                    False   \n",
       "651               0   8.517393                   1                    False   \n",
       "23395             0   7.496097                   1                    False   \n",
       "20201             0  10.714440                   1                    False   \n",
       "\n",
       "       f04__YearQuarter_2009Q3  f04__YearQuarter_2009Q4  \\\n",
       "6                        False                    False   \n",
       "185                      False                    False   \n",
       "372                      False                    False   \n",
       "559                      False                    False   \n",
       "584                      False                    False   \n",
       "...                        ...                      ...   \n",
       "16604                    False                    False   \n",
       "24055                    False                    False   \n",
       "651                      False                    False   \n",
       "23395                    False                    False   \n",
       "20201                    False                    False   \n",
       "\n",
       "       f04__YearQuarter_2010Q1  f04__YearQuarter_2010Q2  \\\n",
       "6                        False                    False   \n",
       "185                      False                    False   \n",
       "372                      False                    False   \n",
       "559                      False                    False   \n",
       "584                      False                    False   \n",
       "...                        ...                      ...   \n",
       "16604                    False                    False   \n",
       "24055                    False                    False   \n",
       "651                      False                    False   \n",
       "23395                    False                    False   \n",
       "20201                    False                    False   \n",
       "\n",
       "       f04__YearQuarter_2010Q3  f04__YearQuarter_2010Q4  ...  \\\n",
       "6                        False                    False  ...   \n",
       "185                      False                    False  ...   \n",
       "372                      False                    False  ...   \n",
       "559                      False                    False  ...   \n",
       "584                      False                    False  ...   \n",
       "...                        ...                      ...  ...   \n",
       "16604                    False                    False  ...   \n",
       "24055                    False                    False  ...   \n",
       "651                      False                    False  ...   \n",
       "23395                    False                    False  ...   \n",
       "20201                    False                    False  ...   \n",
       "\n",
       "       f06__PC375__sentencePC  f06__PC376__sentencePC  f06__PC377__sentencePC  \\\n",
       "6                    0.000846                0.005472               -0.000529   \n",
       "185                  0.008241               -0.005321                0.007848   \n",
       "372                 -0.009183               -0.009091               -0.000953   \n",
       "559                 -0.001648               -0.007339               -0.001597   \n",
       "584                  0.001775               -0.000978                0.000150   \n",
       "...                       ...                     ...                     ...   \n",
       "16604                0.011808                0.001243               -0.006971   \n",
       "24055                0.011570                0.000566               -0.008945   \n",
       "651                  0.006663                0.008468               -0.009823   \n",
       "23395               -0.000367                0.000650                0.011803   \n",
       "20201               -0.007115                0.023709                0.006816   \n",
       "\n",
       "       f06__PC378__sentencePC  f06__PC379__sentencePC  f06__PC380__sentencePC  \\\n",
       "6                   -0.002469                0.007676               -0.003253   \n",
       "185                  0.000785                0.002999               -0.003131   \n",
       "372                 -0.001235               -0.000773                0.007736   \n",
       "559                 -0.003089                0.001160               -0.006445   \n",
       "584                 -0.005342                0.004902                0.008175   \n",
       "...                       ...                     ...                     ...   \n",
       "16604               -0.009105                0.010054                0.006768   \n",
       "24055                0.000957               -0.006621                0.002190   \n",
       "651                  0.000353               -0.002737               -0.004764   \n",
       "23395                0.017459               -0.010777               -0.003733   \n",
       "20201               -0.001531                0.000420               -0.008791   \n",
       "\n",
       "       f06__PC381__sentencePC  f06__PC382__sentencePC  f06__PC383__sentencePC  \\\n",
       "6                   -0.005858           -3.012657e-09           -4.204647e-12   \n",
       "185                 -0.005485           -1.902775e-09           -2.655699e-12   \n",
       "372                 -0.003252           -5.481304e-10           -7.649645e-13   \n",
       "559                 -0.002330            6.281340e-10            8.766529e-13   \n",
       "584                  0.004072            7.977743e-10            1.113446e-12   \n",
       "...                       ...                     ...                     ...   \n",
       "16604               -0.005730            3.752191e-09            5.236717e-12   \n",
       "24055               -0.000248           -1.916849e-10           -2.674701e-13   \n",
       "651                 -0.000034            7.248513e-10            1.011660e-12   \n",
       "23395                0.003847           -2.222395e-09           -3.101696e-12   \n",
       "20201                0.012106            1.727008e-09            2.410180e-12   \n",
       "\n",
       "       f06__PC384__sentencePC  \n",
       "6               -3.546401e-17  \n",
       "185              3.798711e-17  \n",
       "372              5.246079e-18  \n",
       "559             -1.106065e-16  \n",
       "584             -8.206238e-17  \n",
       "...                       ...  \n",
       "16604           -4.937998e-17  \n",
       "24055           -6.110285e-17  \n",
       "651              1.834344e-17  \n",
       "23395            2.421495e-17  \n",
       "20201            8.373799e-17  \n",
       "\n",
       "[1010 rows x 436 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_add"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
